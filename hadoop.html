<!DOCTYPE html>

<html lang="zh-CN">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width" name="viewport"/>
<meta content="#222" name="theme-color"/><meta content="Hexo 6.3.0" name="generator"/>
<link href="/blog/css/main.css" rel="stylesheet"/>
<link crossorigin="anonymous" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" rel="stylesheet"/>
<script class="next-config" data-name="main" type="application/json">{"hostname":"hrfis.me","root":"/blog/","images":"/blog/images","scheme":"Gemini","darkmode":false,"version":"8.16.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":true,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","sidebar":"fadeInLeft"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/blog/js/config.js"></script>
<meta content="重写中
 不作死就不会死。用 Ubuntu + VM Player
 的后果是：隔一段时间系统就会卡死（与 Hadoop 无关），然后 watchdog
 报死锁。
 也可能是笔者最近重新启用了一些 Windows 配置。最可能的问题可能就是
 VMPlayer 的问题。笔者想转用 WSL" name="description"/>
<meta content="article" property="og:type"/>
<meta content="Hadoop" property="og:title"/>
<meta content="https://hrfis.me/blog/hadoop.html" property="og:url"/>
<meta content="若凡的笔记" property="og:site_name"/>
<meta content="重写中
 不作死就不会死。用 Ubuntu + VM Player
 的后果是：隔一段时间系统就会卡死（与 Hadoop 无关），然后 watchdog
 报死锁。
 也可能是笔者最近重新启用了一些 Windows 配置。最可能的问题可能就是
 VMPlayer 的问题。笔者想转用 WSL" property="og:description"/>
<meta content="zh_CN" property="og:locale"/>
<meta content="2024-04-26T09:45:00.000Z" property="article:published_time"/>
<meta content="2024-04-28T14:58:04.116Z" property="article:modified_time"/>
<meta content="Ruofan" property="article:author"/>
<meta content="summary" name="twitter:card"/>
<link href="https://hrfis.me/blog/hadoop" rel="canonical"/>
<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://hrfis.me/blog/hadoop.html","path":"/hadoop.html","title":"Hadoop"}</script>
<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Hadoop | 若凡的笔记</title>
<noscript>
<link href="/blog/css/noscript.css" rel="stylesheet"/>
</noscript>
</head>
<body itemscope="" itemtype="http://schema.org/WebPage">
<div class="headband"></div>
<main class="main">
<div class="column">
<header class="header" itemscope="" itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
<div class="site-nav-toggle">
<div aria-label="切换导航栏" class="toggle" role="button">
<span class="toggle-line"></span>
<span class="toggle-line"></span>
<span class="toggle-line"></span>
</div>
</div>
<div class="site-meta">
<a class="brand" href="/blog/" rel="start">
<i class="logo-line"></i>
<p class="site-title">若凡的笔记</p>
<i class="logo-line"></i>
</a>
</div>
<div class="site-nav-right">
<div aria-label="搜索" class="toggle popup-trigger" role="button">
</div>
</div>
</div>
<nav class="site-nav">
<ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/blog/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/blog/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
</ul>
</nav>
</header>
<aside class="sidebar">
<div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
<ul class="sidebar-nav">
<li class="sidebar-nav-toc">
          文章目录
        </li>
<li class="sidebar-nav-overview">
          站点概览
        </li>
</ul>
<div class="sidebar-panel-container">
<!--noindex-->
<div class="post-toc-wrap sidebar-panel">
<div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%90%AD%E5%BB%BA-hadoop-%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4"><span class="nav-number">1.</span> <span class="nav-text">搭建 Hadoop 完全分布式集群</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%9E%E6%8E%A5-hdfs"><span class="nav-number">2.</span> <span class="nav-text">连接 HDFS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#zookeeper"><span class="nav-number">3.</span> <span class="nav-text">ZooKeeper</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hbase"><span class="nav-number">4.</span> <span class="nav-text">HBase</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C"><span class="nav-number">5.</span> <span class="nav-text">网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ssh"><span class="nav-number">6.</span> <span class="nav-text">SSH</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%AE%E5%BD%95"><span class="nav-number">7.</span> <span class="nav-text">目录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mr"><span class="nav-number">8.</span> <span class="nav-text">MR</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B6%85%E9%93%BE%E6%8E%A5"><span class="nav-number">9.</span> <span class="nav-text">超链接</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8C%81%E4%B9%85%E5%8C%96"><span class="nav-number">10.</span> <span class="nav-text">持久化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%91%BD%E4%BB%A4"><span class="nav-number">10.1.</span> <span class="nav-text">命令</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#all"><span class="nav-number">10.2.</span> <span class="nav-text">all</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#xsync"><span class="nav-number">10.3.</span> <span class="nav-text">xsync</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#myhadoop"><span class="nav-number">10.4.</span> <span class="nav-text">myhadoop</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#zks"><span class="nav-number">10.5.</span> <span class="nav-text">zks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#zkc"><span class="nav-number">10.6.</span> <span class="nav-text">zkc</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%99%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E5%8F%8A%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="nav-number">10.7.</span> <span class="nav-text">写脚本安装软件及配置环境变量</span></a></li></ol></li></ol></div>
</div>
<!--/noindex-->
<div class="site-overview-wrap sidebar-panel">
<div class="site-author animated" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
<p class="site-author-name" itemprop="name">Ruofan</p>
<div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
<nav class="site-state">
<div class="site-state-item site-state-posts">
<a href="/blog/archives/">
<span class="site-state-item-count">34</span>
<span class="site-state-item-name">笔记</span>
</a>
</div>
<div class="site-state-item site-state-categories">
<a href="/blog/categories/">
<span class="site-state-item-count">4</span>
<span class="site-state-item-name">分类</span></a>
</div>
</nav>
</div>
</div>
</div>
</div>
</aside>
</div>
<div class="main-inner post posts-expand">
<div class="post-block">
<article class="post-content" itemscope="" itemtype="http://schema.org/Article" lang="zh-CN">
<link href="https://hrfis.me/blog/hadoop.html" itemprop="mainEntityOfPage"/>
<span hidden="" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
<meta content="/blog/images/avatar.gif" itemprop="image"/>
<meta content="Ruofan" itemprop="name"/>
</span>
<span hidden="" itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
<meta content="若凡的笔记" itemprop="name"/>
<meta content="" itemprop="description"/>
</span>
<span hidden="" itemprop="post" itemscope="" itemtype="http://schema.org/CreativeWork">
<meta content="Hadoop | 若凡的笔记" itemprop="name"/>
<meta content="" itemprop="description"/>
</span>
<header class="post-header">
<h1 class="post-title" itemprop="name headline">
          Hadoop
        </h1>
<div class="post-meta-container">
<div class="post-meta">
<span class="post-meta-item">
<span class="post-meta-item-icon">
<i class="far fa-calendar"></i>
</span>
<span class="post-meta-item-text">发表于</span>
<time datetime="2024-04-26T17:45:00+08:00" itemprop="dateCreated datePublished" title="创建时间：2024-04-26 17:45:00">2024-04-26</time>
</span>
<span class="post-meta-item">
<span class="post-meta-item-icon">
<i class="far fa-calendar-check"></i>
</span>
<span class="post-meta-item-text">更新于</span>
<time datetime="2024-04-28T22:58:04+08:00" itemprop="dateModified" title="修改时间：2024-04-28 22:58:04">2024-04-28</time>
</span>
<span class="post-meta-item">
<span class="post-meta-item-icon">
<i class="far fa-folder"></i>
</span>
<span class="post-meta-item-text">分类于</span>
<span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
<a href="/blog/p/" itemprop="url" rel="index"><span itemprop="name">问题</span></a>
</span>
</span>
</div>
</div>
</header>
<div class="post-body" itemprop="articleBody"><p>重写中</p>
<p>不作死就不会死。用 Ubuntu + VM Player
的后果是：隔一段时间系统就会卡死（与 Hadoop 无关），然后 watchdog
报死锁。</p>
<p>也可能是笔者最近重新启用了一些 Windows 配置。最可能的问题可能就是
VMPlayer 的问题。笔者想转用 WSL</p>
<span id="more"></span>
<p>Hadoop 是一个软件，它是用 Java 写的，需要运行在 Java
虚拟机上。你以后还要通过写 Java 代码来连接它其中的一个组件，叫
HDFS。所有 Java 代码都得过一道 Java 编译器，然后在 JVM（Java
虚拟机）上运行。</p>
<p>我们为什么要装 Linux 虚拟机？</p>
<ol type="1">
<li>模拟分布式集群</li>
<li>生产环境都用 Linux</li>
</ol>
<p>按理来说：</p>
<ol type="1">
<li>Hadoop 需要 JVM 去运行</li>
<li>在 Windows 上照样可以运行 JVM</li>
<li>Hadoop 可以运行在 Windows 上</li>
</ol>
<h2 id="搭建-hadoop-完全分布式集群">搭建 Hadoop 完全分布式集群</h2>
<ol type="1">
<li>下载 Linux 操作系统镜像，可以理解为操作系统的“安装包”。<a href="https://launchpad.net/ubuntu/+cdmirrors" rel="noopener" target="_blank">下载页面（仓库集合）</a>，找到
China。这里使用 <code>ubuntu-22.04.3-live-server-amd64.iso</code></li>
<li>下载一个支持在 Windows 操作系统下运行 Linux
镜像的软件（宿主），它相当于一个没装操作系统的电脑，但是装了引导加载程序
GRUB
<ul>
<li>使用 VM Player <a href="https://customerconnect.vmware.com/cn/downloads/info/slug/desktop_end_user_computing/vmware_workstation_player/" rel="noopener" target="_blank">下载页面</a></li>
<li>使用 WSL（适用于 Windows 的 Linux 子系统）</li>
</ul></li>
<li>在宿主里“创建两台虚拟机”，相当于对这一份镜像，安装了两个新的操作系统，运行在你的宿主和
Windows 操作系统上</li>
<li>配置网络，给虚拟机和物理机搭上鹊桥
<ul>
<li>不同虚拟机采用不同静态 IP</li>
<li>把虚拟机网卡路由到宿主的网关，在
<code>C:\ProgramData\VMware\vmnetnat.conf</code> 查看 VM 的 NAT
网关地址</li>
<li>修改 <code>/etc/hostname</code> <code>/etc/hosts</code>
<code>C:\Windows\System32\drivers\etc\hosts</code></li>
</ul></li>
<li>配置 SSH。<a href="https://wangdoc.com/ssh/" rel="noopener" target="_blank">SSH 教程</a></li>
<li>下载 Hadoop 软件包
<ul>
<li>在虚拟机上直接用 <code>wget</code></li>
<li>用物理机下载它，从物理机的文件系统上再转移到虚拟机的文件系统上（在你的物理机硬盘上表现为
<code>.vmdk</code> 文件）
<ul>
<li>VM Player
有共享文件夹功能，把你物理机硬盘的某一个文件夹挂载到虚拟机的
<code>/mnt/hgfs/Shared</code></li>
<li>如果使用 WSL，你的物理机硬盘会被挂载到虚拟机的
<code>/mnt</code></li>
<li>使用 XFtp 软件，与你的虚拟机进行 SSH 网络协议连接</li>
</ul></li>
</ul></li>
<li>在两台虚拟机上都把软件包解压。<code>/opt</code> 目录是空的，option
的意思，让你自己选择装不装到这里。</li>
<li>修改它们的配置文件，要保证每台机器配置文件内容相同。使用 VSCode 的
Remote-SSH 插件可以直接修改虚拟机内的文件。当 CPU 占用高，写磁盘不到
1MB/s，可能是出问题了在一直写 log。
<ul>
<li><code>hadoop-env.sh</code> 指定 JAVA_HOME，NN、2NN、DN、RM、NM
的用户名，启动 JVM 时的参数</li>
<li><code>core-site.xml</code> 指定 hdfs 的
URI，文件系统存在本地哪个目录，http 登录用户名</li>
<li><code>hdfs-site.xml</code> 指定谁当 NN、2NN，副本个数</li>
<li><code>mapred-site.xml</code> 指定 MR 框架，MR 历史服务器</li>
<li><code>yarn-site.xml</code> 指定 RM，YARN 历史服务器</li>
<li><code>workers</code> 指定谁当 DataNode</li>
</ul></li>
<li>在 NameNode 上执行 <code>hdfs -namenode format</code>，把 Hadoop
的文件系统 HDFS
初始化。在你的物理机文件系统上有一个虚拟机文件系统，在虚拟机文件系统上又有一个
HDFS</li>
</ol>
<h2 id="连接-hdfs">连接 HDFS</h2>
<p>何意？</p>
<p>使用 org.apache.hadoop.fs.FileSystem 这个类的 get 方法，传一个
core-site.xml 里指定的 URI。</p>
<p>在物理机上编码，带上这些依赖，带依赖打成 jar 包，在虚拟机上使用
<code>java -jar xxx.jar</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/><span class="line">3</span><br/><span class="line">4</span><br/><span class="line">5</span><br/><span class="line">6</span><br/><span class="line">7</span><br/><span class="line">8</span><br/><span class="line">9</span><br/><span class="line">10</span><br/><span class="line">11</span><br/><span class="line">12</span><br/><span class="line">13</span><br/><span class="line">14</span><br/><span class="line">15</span><br/></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br/><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br/><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br/><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br/><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br/><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br/><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br/><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br/><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br/><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br/><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br/><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br/><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br/><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br/><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br/></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/><span class="line">3</span><br/><span class="line">4</span><br/><span class="line">5</span><br/><span class="line">6</span><br/><span class="line">7</span><br/><span class="line">8</span><br/><span class="line">9</span><br/><span class="line">10</span><br/><span class="line">11</span><br/><span class="line">12</span><br/><span class="line">13</span><br/><span class="line">14</span><br/><span class="line">15</span><br/><span class="line">16</span><br/><span class="line">17</span><br/><span class="line">18</span><br/><span class="line">19</span><br/><span class="line">20</span><br/><span class="line">21</span><br/><span class="line">22</span><br/></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example;</span><br/><span class="line"></span><br/><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br/><span class="line"><span class="keyword">import</span> java.net.URI;</span><br/><span class="line"><span class="keyword">import</span> java.net.URISyntaxException;</span><br/><span class="line"></span><br/><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br/><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</span><br/><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br/><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br/><span class="line"></span><br/><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">App</span> {</span><br/><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, URISyntaxException {</span><br/><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br/><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">"hdfs://ubuntu101:9820"</span>), conf);</span><br/><span class="line">        FileStatus[] fileStatuses = fs.listStatus(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">"/"</span>));</span><br/><span class="line">        <span class="keyword">for</span> (FileStatus status : fileStatuses) {</span><br/><span class="line">            System.out.println(status.getPath());</span><br/><span class="line">        }</span><br/><span class="line">        fs.close();</span><br/><span class="line">    }</span><br/><span class="line">}</span><br/></pre></td></tr></table></figure>
<h2 id="zookeeper">ZooKeeper</h2>
<p>ZooKeeper
特点是只要有半数以上的节点正常工作，整个集群就能正常工作，所以适合装到奇数台服务器上。</p>
<p>配置 <code>zkData/myid</code></p>
<p>配置 <code>conf/zoo.cfg</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/><span class="line">3</span><br/></pre></td><td class="code"><pre><span class="line">dataDir=/usr/local/zookeeper-3.8.2/zkData</span><br/><span class="line">server.101=master:2888:3888</span><br/><span class="line">server.102=worker1:2888:3888</span><br/></pre></td></tr></table></figure>
<h2 id="hbase">HBase</h2>
<p><code>hbase-env.sh</code> 指定 JAVA_HOME</p>
<p><code>hbase-site.xml</code>
指定是否以分布式运行，数据库根目录是本地文件系统还是 HDFS，Web
端口，Zookeeper 数据目录，HBase
临时目录，不强制执行与流式传输相关的不安全操作</p>
<p>注意：hbase 自带 zookeeper。如果想使用本地已安装的
zookeeper：下次再说（下次再说的意思是永远都不说）</p>
<h2 id="网络">网络</h2>
<p>编辑<code>/etc/netplan</code>下的<code>00-installer-config.yaml</code>文件。<a href="https://netplan.readthedocs.io/en/stable/netplan-tutorial/" rel="noopener" target="_blank">netplan
文档</a></p>
<p>选择<code>192.168.78</code>的依据是：</p>
<ul>
<li>在物理机使用<code>ipconfig</code>命令得到的【VMnet8】的 IPv4
地址<code>192.168.78.1</code></li>
<li>查看 <code>C:\ProgramData\VMware\vmnetnat.conf</code> 里的 NAT
网关地址<code>192.168.78.2</code></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/><span class="line">3</span><br/><span class="line">4</span><br/><span class="line">5</span><br/><span class="line">6</span><br/><span class="line">7</span><br/><span class="line">8</span><br/><span class="line">9</span><br/><span class="line">10</span><br/><span class="line">11</span><br/><span class="line">12</span><br/><span class="line">13</span><br/><span class="line">14</span><br/></pre></td><td class="code"><pre><span class="line"><span class="attr">network:</span></span><br/><span class="line">  <span class="attr">version:</span> <span class="number">2</span></span><br/><span class="line">  <span class="attr">ethernets:</span></span><br/><span class="line">    <span class="attr">ens33:</span></span><br/><span class="line">      <span class="attr">dhcp4:</span> <span class="literal">false</span></span><br/><span class="line">      <span class="attr">dhcp6:</span> <span class="literal">false</span></span><br/><span class="line">      <span class="attr">addresses:</span></span><br/><span class="line">        <span class="bullet">-</span> <span class="number">192.168</span><span class="number">.78</span><span class="number">.101</span><span class="string">/24</span> <span class="comment"># 每台机器设置成不同的</span></span><br/><span class="line">      <span class="attr">routes:</span></span><br/><span class="line">        <span class="bullet">-</span> <span class="attr">to:</span> <span class="string">default</span></span><br/><span class="line">          <span class="attr">via:</span> <span class="number">192.168</span><span class="number">.78</span><span class="number">.2</span></span><br/><span class="line">      <span class="attr">nameservers:</span></span><br/><span class="line">        <span class="attr">addresses:</span></span><br/><span class="line">          <span class="bullet">-</span> <span class="number">192.168</span><span class="number">.78</span><span class="number">.2</span></span><br/></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br/></pre></td><td class="code"><pre><span class="line">sudo netplan try</span><br/></pre></td></tr></table></figure>
<h2 id="ssh">SSH</h2>
<p>两台机器上都执行：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br/></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -m PEM</span><br/></pre></td></tr></table></figure>
<p>笔者这里的版本是
<code>OpenSSH_8.9p1 Ubuntu-3ubuntu0.6, OpenSSL 3.0.2 15 Mar 2022</code>，要加上
<code>-m PEM</code>，确保私钥以 -----BEGIN <strong>RSA</strong> PRIVATE
KEY----- 开头。<a href="https://www.cnblogs.com/simple-li/p/14654812.html" rel="noopener" target="_blank">后续错误</a></p>
<p>两台机器上都执行：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/></pre></td><td class="code"><pre><span class="line">ssh-copy-id ubuntu101</span><br/><span class="line">ssh-copy-id ubuntu102</span><br/></pre></td></tr></table></figure>
<h2 id="目录">目录</h2>
<p>EditLog 和 FsImage 在：</p>
<ul>
<li>NN 的 <code>${hadoop.tmp.dir}/dfs/name/current</code></li>
<li>2NN 的
<code>${hadoop.tmp.dir}/data/dfs/namesecondary/current</code></li>
</ul>
<h2 id="mr">MR</h2>
<h2 id="超链接">超链接</h2>
<ul>
<li><a href="https://www.ruanyifeng.com/blog/2020/08/rsync.html" rel="noopener" target="_blank">rsync
用法教程</a></li>
<li><a href="https://hadoop.apache.org/docs/r3.3.6/hadoop-project-dist/hadoop-common/FileSystemShell.html" rel="noopener" target="_blank">FileSystem
Shell</a></li>
<li><a href="https://hadoop.apache.org/docs/r3.3.6/api/org/apache/hadoop/fs/FileSystem.html" rel="noopener" target="_blank">FileSystem
API</a></li>
<li><a href="https://hadoop.apache.org/docs/r3.3.6/api/org/apache/hadoop/fs/FileUtil.html" rel="noopener" target="_blank">FileUtil
API</a></li>
<li><a href="https://hadoop.apache.org/docs/r3.3.6/api/org/apache/hadoop/fs/FileStatus.html" rel="noopener" target="_blank">FileStatus
API</a></li>
<li><a href="https://zookeeper.apache.org/doc/r3.8.2/zookeeperCLI.html" rel="noopener" target="_blank">zookeeper
CLI</a></li>
<li><a href="https://zookeeper.apache.org/doc/r3.8.2/apidocs/zookeeper-server/index.html" rel="noopener" target="_blank">zookeeper
Server API</a></li>
</ul>
<h2 id="持久化">持久化</h2>
<h3 id="命令">命令</h3>
<p>所谓使用命令，就是使用别人已经写好的软件。</p>
<p>环境变量 <code>PATH</code> 和物理路径，就是域名和 IP
地址的区别，要过一道中间商。域名和 IP 地址的中间商叫
DNS，<code>PATH</code> 和物理路径的中间商叫命令行解释器。</p>
<p>你输入一个命令，命令行解释器会在 <code>PATH</code>
里寻找你命令的源文件入口在哪，然后向它传递参数。</p>
<p>你可以使用 <code>which xxx</code> 或
<code>readlink -f $(which xxx)</code> 找你的命令源文件在哪里。</p>
<p>查看虚拟机的 IP 地址：<code>ifconfig</code></p>
<p>查看 JVM 进程：<code>jps</code></p>
<p>start-all.sh</p>
<p>stop-all.sh</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br/></pre></td><td class="code"><pre><span class="line">mapred --daemon start historyserver</span><br/></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br/></pre></td><td class="code"><pre><span class="line">hadoop jar <span class="variable">$HADOOP_HOME</span>/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar wordcount /wcinput /wcoutput</span><br/></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br/></pre></td><td class="code"><pre><span class="line">hdfs oev -p XML -i edits_xxxx -o ./edits_xxxx.xml</span><br/></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br/></pre></td><td class="code"><pre><span class="line">hdfs oiv -p XML -i fsimage_xxxx -o ./fsimage_xxxx.xml</span><br/></pre></td></tr></table></figure>
<h3 id="all">all</h3>
<p>对集群的所有机器执行操作。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/><span class="line">3</span><br/><span class="line">4</span><br/><span class="line">5</span><br/><span class="line">6</span><br/><span class="line">7</span><br/><span class="line">8</span><br/><span class="line">9</span><br/><span class="line">10</span><br/><span class="line">11</span><br/></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br/><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -eq 0 ]; <span class="keyword">then</span></span><br/><span class="line">    <span class="built_in">echo</span> <span class="string">"Error: Please provide at least one argument."</span></span><br/><span class="line">    <span class="built_in">exit</span> 1</span><br/><span class="line"><span class="keyword">else</span></span><br/><span class="line">    <span class="keyword">for</span> host <span class="keyword">in</span> ubuntu101 ubuntu102</span><br/><span class="line">    <span class="keyword">do</span></span><br/><span class="line">        <span class="built_in">echo</span> <span class="string">"============ <span class="variable">$host</span> ==========="</span></span><br/><span class="line">        ssh <span class="variable">$host</span> <span class="string">"<span class="variable">$@</span>"</span></span><br/><span class="line">    <span class="keyword">done</span></span><br/><span class="line"><span class="keyword">fi</span></span><br/></pre></td></tr></table></figure>
<h3 id="xsync">xsync</h3>
<p>同步文件/目录到所有机器</p>
<p>先测试从一台机器上同步到另一台机器上：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br/></pre></td><td class="code"><pre><span class="line">rsync -av /path/to/src ubuntu102:/path/to/dst</span><br/></pre></td></tr></table></figure>
<p>从某台机器上同步到所有机器上：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/><span class="line">3</span><br/><span class="line">4</span><br/><span class="line">5</span><br/><span class="line">6</span><br/><span class="line">7</span><br/><span class="line">8</span><br/><span class="line">9</span><br/><span class="line">10</span><br/><span class="line">11</span><br/><span class="line">12</span><br/><span class="line">13</span><br/><span class="line">14</span><br/><span class="line">15</span><br/><span class="line">16</span><br/><span class="line">17</span><br/><span class="line">18</span><br/><span class="line">19</span><br/><span class="line">20</span><br/><span class="line">21</span><br/><span class="line">22</span><br/><span class="line">23</span><br/></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br/><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -lt 1 ]</span><br/><span class="line"><span class="keyword">then</span></span><br/><span class="line">    <span class="built_in">echo</span> Not Enough Argument!</span><br/><span class="line">    <span class="built_in">exit</span>;</span><br/><span class="line"><span class="keyword">fi</span></span><br/><span class="line"></span><br/><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> ubuntu101 ubuntu102 ubuntu103</span><br/><span class="line"><span class="keyword">do</span></span><br/><span class="line">    <span class="built_in">echo</span> ==================== <span class="variable">$host</span> ====================</span><br/><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> <span class="variable">$@</span></span><br/><span class="line">    <span class="keyword">do</span></span><br/><span class="line">        <span class="keyword">if</span> [ -e <span class="variable">$file</span> ]</span><br/><span class="line">        <span class="keyword">then</span></span><br/><span class="line">            pdir=$(<span class="built_in">cd</span> -P $(<span class="built_in">dirname</span> <span class="variable">$file</span>); <span class="built_in">pwd</span>)</span><br/><span class="line">            fname=$(<span class="built_in">basename</span> <span class="variable">$file</span>)</span><br/><span class="line">            ssh <span class="variable">$host</span> <span class="string">"mkdir -p <span class="variable">$pdir</span>"</span></span><br/><span class="line">            rsync -av <span class="variable">$pdir</span>/<span class="variable">$fname</span> <span class="variable">$host</span>:<span class="variable">$pdir</span></span><br/><span class="line">        <span class="keyword">else</span></span><br/><span class="line">            <span class="built_in">echo</span> <span class="variable">$file</span> does not exists!</span><br/><span class="line">        <span class="keyword">fi</span></span><br/><span class="line">    <span class="keyword">done</span></span><br/><span class="line"><span class="keyword">done</span></span><br/></pre></td></tr></table></figure>
<h3 id="myhadoop">myhadoop</h3>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/><span class="line">3</span><br/><span class="line">4</span><br/><span class="line">5</span><br/><span class="line">6</span><br/><span class="line">7</span><br/><span class="line">8</span><br/><span class="line">9</span><br/><span class="line">10</span><br/><span class="line">11</span><br/><span class="line">12</span><br/><span class="line">13</span><br/><span class="line">14</span><br/><span class="line">15</span><br/><span class="line">16</span><br/><span class="line">17</span><br/><span class="line">18</span><br/><span class="line">19</span><br/><span class="line">20</span><br/><span class="line">21</span><br/><span class="line">22</span><br/><span class="line">23</span><br/><span class="line">24</span><br/><span class="line">25</span><br/><span class="line">26</span><br/><span class="line">27</span><br/><span class="line">28</span><br/><span class="line">29</span><br/><span class="line">30</span><br/><span class="line">31</span><br/></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br/><span class="line"><span class="keyword">case</span> <span class="string">"<span class="variable">$1</span>"</span> <span class="keyword">in</span></span><br/><span class="line">    <span class="string">"start"</span>)</span><br/><span class="line">        <span class="built_in">echo</span> <span class="string">"============ 启动 hadoop 集群 ============"</span></span><br/><span class="line"></span><br/><span class="line">        <span class="built_in">echo</span> <span class="string">"-------- 启动 HDFS --------"</span></span><br/><span class="line">        ssh <span class="string">"ubuntu101"</span> <span class="string">"<span class="variable">$HADOOP_HOME</span>/sbin/start-dfs.sh"</span></span><br/><span class="line">        <span class="built_in">echo</span> <span class="string">"-------- 启动 YARN --------"</span></span><br/><span class="line">        ssh <span class="string">"ubuntu102"</span> <span class="string">"<span class="variable">$HADOOP_HOME</span>/sbin/start-yarn.sh"</span></span><br/><span class="line">        <span class="built_in">echo</span> <span class="string">"-------- 启动 historyserver --------"</span></span><br/><span class="line">        ssh <span class="string">"ubuntu102"</span> <span class="string">"<span class="variable">$HADOOP_HOME</span>/bin/mapred --daemon start historyserver"</span></span><br/><span class="line"></span><br/><span class="line">        all jps</span><br/><span class="line">        ;;</span><br/><span class="line">    <span class="string">"stop"</span>)</span><br/><span class="line">        <span class="built_in">echo</span> <span class="string">"============ 关闭 hadoop 集群 ============"</span></span><br/><span class="line"></span><br/><span class="line">        <span class="built_in">echo</span> <span class="string">"-------- 关闭 historyserver --------"</span></span><br/><span class="line">        ssh <span class="string">"ubuntu102"</span> <span class="string">"<span class="variable">$HADOOP_HOME</span>/bin/mapred --daemon stop historyserver"</span></span><br/><span class="line">        <span class="built_in">echo</span> <span class="string">"-------- 关闭 YARN --------"</span></span><br/><span class="line">        ssh <span class="string">"ubuntu102"</span> <span class="string">"<span class="variable">$HADOOP_HOME</span>/sbin/stop-yarn.sh"</span></span><br/><span class="line">        <span class="built_in">echo</span> <span class="string">"-------- 关闭 HDFS --------"</span></span><br/><span class="line">        ssh <span class="string">"ubuntu101"</span> <span class="string">"<span class="variable">$HADOOP_HOME</span>/sbin/stop-dfs.sh"</span></span><br/><span class="line"></span><br/><span class="line">        all jps</span><br/><span class="line">        ;;</span><br/><span class="line">    *)</span><br/><span class="line">        <span class="built_in">echo</span> <span class="string">"Invalid parameter!"</span></span><br/><span class="line">        <span class="built_in">exit</span> 1</span><br/><span class="line">        ;;</span><br/><span class="line"><span class="keyword">esac</span></span><br/></pre></td></tr></table></figure>
<h3 id="zks">zks</h3>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/><span class="line">3</span><br/><span class="line">4</span><br/><span class="line">5</span><br/><span class="line">6</span><br/><span class="line">7</span><br/><span class="line">8</span><br/><span class="line">9</span><br/><span class="line">10</span><br/><span class="line">11</span><br/><span class="line">12</span><br/><span class="line">13</span><br/><span class="line">14</span><br/><span class="line">15</span><br/><span class="line">16</span><br/><span class="line">17</span><br/><span class="line">18</span><br/><span class="line">19</span><br/><span class="line">20</span><br/><span class="line">21</span><br/><span class="line">22</span><br/><span class="line">23</span><br/></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br/><span class="line"></span><br/><span class="line">ZK_HOME=<span class="string">"/opt/zookeeper-3.8.2"</span></span><br/><span class="line">ZKS_SH=<span class="string">"<span class="variable">$ZK_HOME</span>/bin/zkServer.sh"</span></span><br/><span class="line">servers=<span class="string">"ubuntu101 ubuntu102"</span></span><br/><span class="line"></span><br/><span class="line"><span class="built_in">echo</span> -e <span class="string">"\n"</span></span><br/><span class="line"></span><br/><span class="line"></span><br/><span class="line"><span class="comment"># 参数 $1 是操作名，$2 是主机名</span></span><br/><span class="line"><span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$2</span>"</span> ]; <span class="keyword">then</span></span><br/><span class="line">    <span class="comment"># 如果指定了主机名，对指定主机操作</span></span><br/><span class="line">    <span class="built_in">echo</span> ------ zkServer <span class="variable">$2</span> <span class="variable">$1</span> ------</span><br/><span class="line">    ssh <span class="variable">$2</span> <span class="variable">$ZKS_SH</span> <span class="variable">$1</span></span><br/><span class="line">    <span class="built_in">echo</span> -e <span class="string">"\n"</span></span><br/><span class="line"><span class="keyword">else</span></span><br/><span class="line">    <span class="comment"># 如果没有指定主机名，就对所有主机操作</span></span><br/><span class="line">    <span class="keyword">for</span> server <span class="keyword">in</span> <span class="variable">$servers</span>; <span class="keyword">do</span></span><br/><span class="line">        <span class="built_in">echo</span> ------ zkServer <span class="variable">$server</span> <span class="variable">$1</span> ------</span><br/><span class="line">        ssh <span class="variable">$server</span> <span class="variable">$ZKS_SH</span> <span class="variable">$1</span></span><br/><span class="line">        <span class="built_in">echo</span> -e <span class="string">"\n"</span></span><br/><span class="line">    <span class="keyword">done</span></span><br/><span class="line"><span class="keyword">fi</span></span><br/></pre></td></tr></table></figure>
<h3 id="zkc">zkc</h3>
<p>就是把自带的脚本 <code>zkCli.sh</code> 再封装一层</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/><span class="line">3</span><br/><span class="line">4</span><br/><span class="line">5</span><br/><span class="line">6</span><br/><span class="line">7</span><br/></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br/><span class="line"></span><br/><span class="line">ZK_HOME=<span class="string">"/opt/zookeeper-3.8.2"</span></span><br/><span class="line">ZKC_SH=<span class="string">"<span class="variable">$ZK_HOME</span>/bin/zkCli.sh"</span></span><br/><span class="line">servers=<span class="string">"ubuntu101 ubuntu102"</span></span><br/><span class="line"></span><br/><span class="line"><span class="string">"<span class="variable">$ZKC_SH</span>"</span> -server $(hostname)</span><br/></pre></td></tr></table></figure>
<h3 id="写脚本安装软件及配置环境变量">写脚本安装软件及配置环境变量</h3>
<p>其中，安装 OpenJDK 是按照 <a href="https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions" rel="noopener" target="_blank">https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions</a>
里的说明，指向 <a href="https://github.com/apache/hadoop/blob/rel/release-3.2.1/dev-support/docker/Dockerfile#L92" rel="noopener" target="_blank">https://github.com/apache/hadoop/blob/rel/release-3.2.1/dev-support/docker/Dockerfile#L92</a>
里的命令。</p>
<p>笔者彼时没有注意：在链接里有“Dockerfile”这个单词。Docker
等以后有时间再研究。（有时间再研究的意思是永远都不）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/><span class="line">3</span><br/><span class="line">4</span><br/><span class="line">5</span><br/><span class="line">6</span><br/><span class="line">7</span><br/><span class="line">8</span><br/><span class="line">9</span><br/><span class="line">10</span><br/><span class="line">11</span><br/><span class="line">12</span><br/><span class="line">13</span><br/><span class="line">14</span><br/><span class="line">15</span><br/><span class="line">16</span><br/><span class="line">17</span><br/><span class="line">18</span><br/><span class="line">19</span><br/><span class="line">20</span><br/><span class="line">21</span><br/><span class="line">22</span><br/></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 JDK</span></span><br/><span class="line">sudo apt-get update;</span><br/><span class="line">sudo apt-get install openjdk-8-jdk libbcprov-java;</span><br/><span class="line">sudo apt-get clean;</span><br/><span class="line"><span class="comment"># 存放 Hadoop 压缩包的位置</span></span><br/><span class="line"><span class="built_in">cd</span>;</span><br/><span class="line"><span class="comment"># 解压，删除（这两句笔者执行的时候没执行上，重启后手动执行）</span></span><br/><span class="line">sudo tar -zxvf hadoop-3.3.6.tar.gz -C /opt;</span><br/><span class="line">sudo <span class="built_in">rm</span> hadoop-3.3.6.tar.gz;</span><br/><span class="line"><span class="comment"># 写环境变量，建议用VSCode写，把每个环境变量分开</span></span><br/><span class="line"><span class="comment"># env 查看所有环境变量</span></span><br/><span class="line"><span class="comment"># echo $NAME 查看某个</span></span><br/><span class="line">JAVA_HOME=<span class="string">"/lib/jvm/java-1.8.0-openjdk-amd64"</span>;</span><br/><span class="line">HADOOP_HOME=<span class="string">"/opt/hadoop-3.3.6"</span>;</span><br/><span class="line">text=<span class="string">"export JAVA_HOME=<span class="variable">$JAVA_HOME</span></span></span><br/><span class="line"><span class="string">export HADOOP_HOME=<span class="variable">$HADOOP_HOME</span></span></span><br/><span class="line"><span class="string">export PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin:<span class="variable">$JAVA_HOME</span>/bin</span></span><br/><span class="line"><span class="string">"</span>;</span><br/><span class="line">sudo <span class="built_in">echo</span> <span class="string">"<span class="variable">$text</span>"</span> &gt;&gt; .bashrc;</span><br/><span class="line"><span class="comment"># 应用，重启</span></span><br/><span class="line"><span class="built_in">source</span> .bashrc;</span><br/><span class="line">reboot;</span><br/></pre></td></tr></table></figure>
</div>
<footer class="post-footer">
<div class="post-nav">
<div class="post-nav-item">
<a href="/blog/python.html" rel="prev" title="Python">
<i class="fa fa-chevron-left"></i> Python
                </a>
</div>
<div class="post-nav-item">
</div>
</div>
</footer>
</article>
</div>
</div>
</main>
<footer class="footer">
<div class="footer-inner">
<div class="copyright">
  2023 – 
  <span itemprop="copyrightYear">2024</span>
<span class="with-love">
<i class="fa fa-heart"></i>
</span>
<span class="author" itemprop="copyrightHolder">Ruofan</span>
</div>
</div>
</footer>
<div aria-label="返回顶部" class="back-to-top" role="button">
<i class="fa fa-arrow-up fa-lg"></i>
<span>0%</span>
</div>
<div class="reading-progress-bar"></div>
<noscript>
<div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>
<script crossorigin="anonymous" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js"></script>
<script crossorigin="anonymous" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js"></script>
<script src="/blog/js/comments.js"></script><script src="/blog/js/utils.js"></script><script src="/blog/js/next-boot.js"></script>
<script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.4.3/mermaid.min.js","integrity":"sha256-e0o3JYsdjqKajf9eOe22FhioYSz9WofRY4dLKo3F6do="}}</script>
<script src="/blog/js/third-party/tags/mermaid.js"></script>
<script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/blog/js/third-party/math/mathjax.js"></script>
<script crossorigin="anonymous" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js"></script>
<script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":false,"delay":true,"timeout":3000,"priority":true,"url":"https://hrfis.me/blog/hadoop.html"}</script>
<script src="/blog/js/third-party/quicklink.js"></script>
</body>
</html>
